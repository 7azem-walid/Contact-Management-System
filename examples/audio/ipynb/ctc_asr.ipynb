{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7azem-walid/Contact-Management-System/blob/main/examples/audio/ipynb/ctc_asr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer tensorflow-addons"
      ],
      "metadata": {
        "id": "vHGZmEtfKqti",
        "outputId": "c455295f-c452-420a-d41e-c000308711b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.13.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (24.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (2.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall keras -y  # Remove standalone keras if present"
      ],
      "metadata": {
        "id": "DuAq8zclKqq4",
        "outputId": "7dddade4-97c7-4025-dad3-e92e3c2b16d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: keras 3.9.2\n",
            "Uninstalling keras-3.9.2:\n",
            "  Successfully uninstalled keras-3.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "ZEQ8iGNXKqoO",
        "outputId": "74b055dd-c643-4c21-e830-59dc6a0458e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Collecting keras>=3.5.0 (from tensorflow)\n",
            "  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Using cached keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
            "Installing collected packages: keras\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from jiwer import wer\n"
      ],
      "metadata": {
        "id": "iTtOTBr5KqlW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and prepare dataset\n",
        "data_url = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
        "data_path = tf.keras.utils.get_file(\"LJSpeech-1.1\", data_url, untar=True)\n",
        "wavs_path = data_path + \"/wavs/\"\n",
        "metadata_path = data_path + \"/metadata.csv\""
      ],
      "metadata": {
        "id": "kS2UJgdvKqif",
        "outputId": "daefe38a-c49e-4fc5-f6be-7d005f918daf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "\u001b[1m2748572632/2748572632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read metadata\n",
        "metadata_df = pd.read_csv(metadata_path, sep=\"|\", header=None, quoting=3)\n",
        "metadata_df.columns = [\"file_name\", \"transcription\", \"normalized_transcription\"]\n",
        "metadata_df = metadata_df[[\"file_name\", \"normalized_transcription\"]]\n",
        "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "39vVkrvzXHzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset\n",
        "split = int(len(metadata_df) * 0.90)\n",
        "df_train = metadata_df[:split]\n",
        "df_val = metadata_df[split:]\n",
        "\n",
        "print(f\"Training set size: {len(df_train)}\")\n",
        "print(f\"Validation set size: {len(df_val)}\")\n"
      ],
      "metadata": {
        "id": "iELPgPo8XL6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Character processing\n",
        "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
        "char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
        "num_to_char = keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n",
        "\n",
        "print(f\"Vocabulary: {char_to_num.get_vocabulary()} (size={char_to_num.vocabulary_size()})\")"
      ],
      "metadata": {
        "id": "NsBGTWBENCZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio processing parameters\n",
        "frame_length = 256\n",
        "frame_step = 160\n",
        "fft_length = 384\n",
        "\n",
        "def encode_single_sample(wav_file, label):\n",
        "    # Process audio\n",
        "    file = tf.io.read_file(wavs_path + wav_file + \".wav\")\n",
        "    audio, _ = tf.audio.decode_wav(file)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    audio = tf.cast(audio, tf.float32)\n",
        "\n",
        "    spectrogram = tf.signal.stft(\n",
        "        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
        "    )\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
        "\n",
        "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
        "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
        "\n",
        "    # Process label\n",
        "    label = tf.strings.lower(label)\n",
        "    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
        "    label = char_to_num(label)\n",
        "\n",
        "    return spectrogram, label"
      ],
      "metadata": {
        "id": "XH7Ung9HNEeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "batch_size = 32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_train[\"file_name\"]), list(df_train[\"normalized_transcription\"]))\n",
        "train_dataset = (\n",
        "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_val[\"file_name\"]), list(df_val[\"normalized_transcription\"]))\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "ObRYjAs1UrCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Model Components\n",
        "class PositionalEncoding(layers.Layer):\n",
        "    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n",
        "        super().__init__(dtype=dtype, **kwargs)\n",
        "        if max_dims % 2 == 1: max_dims += 1\n",
        "        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
        "        pos_emb = np.empty((1, max_steps, max_dims))\n",
        "        pos_emb[0, :, ::2] = np.sin(p / 10000**(2 * i / max_dims)).T\n",
        "        pos_emb[0, :, 1::2] = np.cos(p / 10000**(2 * i / max_dims)).T\n",
        "        self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        shape = tf.shape(inputs)\n",
        "        return inputs + self.positional_embedding[:, :shape[-2], :shape[-1]]\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential([\n",
        "            layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.feed_forward_dim = feed_forward_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential([\n",
        "            layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.dropout_1 = layers.Dropout(dropout_rate)\n",
        "        self.dropout_2 = layers.Dropout(dropout_rate)\n",
        "        self.dropout_3 = layers.Dropout(dropout_rate)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, training, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask,\n",
        "            training=training,\n",
        "        )\n",
        "        attention_output_1 = self.dropout_1(attention_output_1, training=training)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "            training=training,\n",
        "        )\n",
        "        attention_output_2 = self.dropout_2(attention_output_2, training=training)\n",
        "        attention_output_2 = self.layernorm_2(attention_output_1 + attention_output_2)\n",
        "\n",
        "        ffn_output = self.ffn(attention_output_2)\n",
        "        ffn_output = self.dropout_3(ffn_output, training=training)\n",
        "        return self.layernorm_3(attention_output_2 + ffn_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "def build_model():\n",
        "    # Encoder\n",
        "    encoder_inputs = keras.Input(shape=(None, fft_length // 2 + 1), name=\"encoder_inputs\")\n",
        "    x = layers.Conv1D(256, 11, strides=2, padding=\"same\", activation=\"relu\")(encoder_inputs)\n",
        "    x = layers.Conv1D(256, 11, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv1D(256, 11, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    encoder_outputs = TransformerEncoder(256, 4, 1024)(x)\n",
        "    encoder = keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = keras.Input(shape=(None,), name=\"decoder_inputs\")\n",
        "    encoded_seq_inputs = keras.Input(shape=(None, 256), name=\"decoder_state_inputs\")\n",
        "    x = layers.Embedding(char_to_num.vocabulary_size(), 256)(decoder_inputs)\n",
        "    x = PositionalEncoding(200, 256)(x)\n",
        "    x = TransformerDecoder(256, 4, 1024)(x, encoded_seq_inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    decoder_outputs = layers.Dense(char_to_num.vocabulary_size(), activation=\"softmax\")(x)\n",
        "    decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs, name=\"decoder\")\n",
        "\n",
        "    # Combined model\n",
        "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "    transformer = keras.Model(\n",
        "        [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        "    )\n",
        "\n",
        "    return transformer\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "a0YI5KfuUy8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate schedule\n",
        "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps**-1.5)\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "learning_rate = CustomSchedule(256)\n",
        "optimizer = keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "# Loss and metrics\n",
        "def loss_fn(y_true, y_pred):\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)(y_true, y_pred)\n",
        "    mask = tf.cast(tf.not_equal(y_true, 0), dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    preds = tf.argmax(y_pred, axis=-1)\n",
        "    preds = tf.cast(preds, dtype=y_true.dtype)\n",
        "    matches = tf.cast(tf.equal(y_true, preds), dtype=tf.float32)\n",
        "    mask = tf.cast(tf.not_equal(y_true, 0), dtype=matches.dtype)\n",
        "    return tf.reduce_sum(matches) / tf.reduce_sum(mask)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[accuracy_fn])\n",
        "\n",
        "# Training\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "predictions = []\n",
        "targets = []\n",
        "for batch in validation_dataset.take(20):\n",
        "    X, y = batch\n",
        "    batch_predictions = model.predict(X)\n",
        "    batch_predictions = tf.argmax(batch_predictions, axis=-1)\n",
        "    for pred, label in zip(batch_predictions, y):\n",
        "        pred_text = tf.strings.reduce_join(num_to_char(pred)).numpy().decode(\"utf-8\")\n",
        "        label_text = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        predictions.append(pred_text)\n",
        "        targets.append(label_text)\n",
        "\n",
        "wer_score = wer(targets, predictions)\n",
        "print(\"-\" * 100)\n",
        "print(f\"Final Word Error Rate: {wer_score:.4f}\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Target: {targets[i]}\")\n",
        "    print(f\"Prediction: {predictions[i]}\")\n",
        "    print(\"-\" * 100)"
      ],
      "metadata": {
        "id": "2ms74hO6KlK2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ctc_asr",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}